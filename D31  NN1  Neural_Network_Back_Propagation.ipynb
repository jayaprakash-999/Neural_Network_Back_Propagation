{"cells":[{"cell_type":"code","source":["!pip install keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5JcmmpGIqESC","outputId":"5044aa88-e8e9-49ac-e3cb-ff3c97dadb21","executionInfo":{"status":"ok","timestamp":1732641368280,"user_tz":-330,"elapsed":3303,"user":{"displayName":"Jaya Prakash","userId":"11498912294217054029"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NHCNnm8Wp3lV"},"outputs":[],"source":["# Create your first MLP in Keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import numpy\n","\n","# This two are very important in newral network\n","\"\"\"\n","#   imports the Sequential class ---> from keras.models\n","##  keras is a deep learning library that makes it easier to build and train neural networks\n","    The Sequential class is used to create a linear stack of layers for your neural network, where each layer feeds into the next.\n","    This is a common way to structure a Multilayer Perceptron (MLP)\n","\n","\"\"\"\n","##   Dense layers are the core building blocks of MLPs. In a Dense layer, every neuron is connected to every neuron in the previous layer.\n","#    These connections are what allow the network to learn complex patterns.\n","\n","#    numpy is a fundamental library for scientific computing in Python.\n","##   It's used for handling arrays and matrices of numerical data, which are essential for working with neural networks."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7YUK47W-p3lW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"119dfb3a-a83d-484b-df1f-b655faa8e805","executionInfo":{"status":"ok","timestamp":1732641374646,"user_tz":-330,"elapsed":14,"user":{"displayName":"Jaya Prakash","userId":"11498912294217054029"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n","       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n","       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n","       ...,\n","       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n","       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n","       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"]},"metadata":{},"execution_count":3}],"source":["# fix random seed for reproducibility\n","seed = 7\n","numpy.random.seed(seed)\n","# load pima indians dataset\n","dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n","# split into input (X) and output (Y) variables\n","X = dataset[:,0:8]\n","Y = dataset[:,8]\n","dataset\n","\n","# Y is a class is aperson is a diabites"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mborI_N4p3lX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fa9ec9d7-7b53-4ddd-e043-9acc0e2be2f1","executionInfo":{"status":"ok","timestamp":1732641374646,"user_tz":-330,"elapsed":12,"user":{"displayName":"Jaya Prakash","userId":"11498912294217054029"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}],"source":["# create model\n","model = Sequential()\n","model.add(Dense(12, input_dim=8, activation='relu'))\n","model.add(Dense(8, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# This line creates a Sequential model. A Sequential model in Keras is a linear stack of layers, where you add layers one after the other.\n","# It's like building a tower, where each layer is stacked on top of the previous one.\n","\n","# sequential connection is conneted (becase 3 layer connection is required )\n","# Dence ---> in each layer\n","# Dence ---> 1st layer 12 nodes input layer precption\n","# input_dimensions = 8  ---> independent variables are 8\n","# activation function ='relu' ( Stright line , range(0,max) )\n","\n","# Hidden Layer ---> 8 nodes input precptions\n","\n","# out put layer ---> 1 nodes output layer (dependent layer)  , sigmoid ( Range 0,1)\n","\n","# (remove)init ==kernel_initializer ---> weights intializer"]},{"cell_type":"markdown","metadata":{"id":"kNBOMOOwp3lX"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0VgnpVUPp3lY"},"outputs":[],"source":["# Compile model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","##  model.compile(...): (Put every thing to gether) This is a function in Keras that configures the model for training.\n","#   You provide it with the settings it needs to learn from your data\n","\n","#  loss is a required argument in model.compile().\n","#  'binary_crossentropy' is a specific loss function used for binary classification problems\n","## (where the output is either 0 or 1), sigmoid activation in the output layer produce)\n","\n","#  'adam' is a popular optimization algorithm.\n","#  The optimizer determines how the model's internal parameters\n","## (weights and biases) are updated during training to reduce the loss.\n","\n","\n","# metrics is an optional argument (but highly recommended).\n","# ['accuracy'] specifies that you want to track the accuracy of the model during training.\n","\"\"\"\n","# Compiling all net work in a single space\n","# Loss = It is not sure to take binary_crossentropy (where the output is either 0 or 1), sigmoid activation in the output layer produce)\n","# optimizer  --> Is another required argument\n","# metric is a choic --> ( tuned )\n","# matric is choice ---> To find fitting accuracy\n","\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k6MWsRofp3lZ","outputId":"0e2bfbb8-b15a-4a0f-8148-19b390f8d036","executionInfo":{"status":"ok","timestamp":1732641395507,"user_tz":-330,"elapsed":20869,"user":{"displayName":"Jaya Prakash","userId":"11498912294217054029"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.3779 - loss: 7.0288 - val_accuracy: 0.4606 - val_loss: 2.7370\n","Epoch 2/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4726 - loss: 2.5632 - val_accuracy: 0.4331 - val_loss: 1.9923\n","Epoch 3/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4129 - loss: 1.8806 - val_accuracy: 0.4409 - val_loss: 1.5399\n","Epoch 4/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4221 - loss: 1.6718 - val_accuracy: 0.6102 - val_loss: 1.1678\n","Epoch 5/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5568 - loss: 1.3674 - val_accuracy: 0.6102 - val_loss: 0.8675\n","Epoch 6/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5773 - loss: 0.9979 - val_accuracy: 0.6772 - val_loss: 0.7469\n","Epoch 7/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6165 - loss: 0.9097 - val_accuracy: 0.6929 - val_loss: 0.7191\n","Epoch 8/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6373 - loss: 0.7807 - val_accuracy: 0.6654 - val_loss: 0.6990\n","Epoch 9/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6484 - loss: 0.7592 - val_accuracy: 0.7047 - val_loss: 0.6676\n","Epoch 10/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6491 - loss: 0.7699 - val_accuracy: 0.7244 - val_loss: 0.6282\n","Epoch 11/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6755 - loss: 0.7615 - val_accuracy: 0.6969 - val_loss: 0.6258\n","Epoch 12/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6473 - loss: 0.6838 - val_accuracy: 0.7323 - val_loss: 0.6109\n","Epoch 13/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7114 - loss: 0.6372 - val_accuracy: 0.7402 - val_loss: 0.6049\n","Epoch 14/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6686 - loss: 0.6522 - val_accuracy: 0.7520 - val_loss: 0.6011\n","Epoch 15/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6980 - loss: 0.6163 - val_accuracy: 0.7244 - val_loss: 0.6059\n","Epoch 16/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6739 - loss: 0.6563 - val_accuracy: 0.7165 - val_loss: 0.5937\n","Epoch 17/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7062 - loss: 0.6038 - val_accuracy: 0.7126 - val_loss: 0.6052\n","Epoch 18/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6744 - loss: 0.6441 - val_accuracy: 0.7087 - val_loss: 0.6106\n","Epoch 19/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6873 - loss: 0.6447 - val_accuracy: 0.7047 - val_loss: 0.5934\n","Epoch 20/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6644 - loss: 0.6451 - val_accuracy: 0.7323 - val_loss: 0.5918\n","Epoch 21/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6857 - loss: 0.6094 - val_accuracy: 0.7165 - val_loss: 0.5874\n","Epoch 22/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6816 - loss: 0.6178 - val_accuracy: 0.7283 - val_loss: 0.5873\n","Epoch 23/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7194 - loss: 0.5761 - val_accuracy: 0.7087 - val_loss: 0.5844\n","Epoch 24/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7179 - loss: 0.6204 - val_accuracy: 0.6850 - val_loss: 0.6196\n","Epoch 25/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6964 - loss: 0.6321 - val_accuracy: 0.7205 - val_loss: 0.5906\n","Epoch 26/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7141 - loss: 0.6191 - val_accuracy: 0.7205 - val_loss: 0.5821\n","Epoch 27/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7179 - loss: 0.5839 - val_accuracy: 0.7126 - val_loss: 0.5799\n","Epoch 28/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7146 - loss: 0.5857 - val_accuracy: 0.7165 - val_loss: 0.5768\n","Epoch 29/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7192 - loss: 0.5833 - val_accuracy: 0.7244 - val_loss: 0.5789\n","Epoch 30/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7193 - loss: 0.5909 - val_accuracy: 0.7047 - val_loss: 0.5980\n","Epoch 31/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7377 - loss: 0.5734 - val_accuracy: 0.7205 - val_loss: 0.5869\n","Epoch 32/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.5571 - val_accuracy: 0.7165 - val_loss: 0.5763\n","Epoch 33/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7106 - loss: 0.5798 - val_accuracy: 0.7087 - val_loss: 0.5738\n","Epoch 34/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7076 - loss: 0.5878 - val_accuracy: 0.7205 - val_loss: 0.5802\n","Epoch 35/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6958 - loss: 0.5984 - val_accuracy: 0.7165 - val_loss: 0.5834\n","Epoch 36/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7138 - loss: 0.6025 - val_accuracy: 0.7047 - val_loss: 0.5982\n","Epoch 37/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6884 - loss: 0.5943 - val_accuracy: 0.7008 - val_loss: 0.5727\n","Epoch 38/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6995 - loss: 0.5981 - val_accuracy: 0.7126 - val_loss: 0.5720\n","Epoch 39/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7073 - loss: 0.5880 - val_accuracy: 0.7244 - val_loss: 0.5799\n","Epoch 40/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7164 - loss: 0.5685 - val_accuracy: 0.7244 - val_loss: 0.5830\n","Epoch 41/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6771 - loss: 0.6229 - val_accuracy: 0.7008 - val_loss: 0.5982\n","Epoch 42/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6879 - loss: 0.6010 - val_accuracy: 0.7165 - val_loss: 0.5718\n","Epoch 43/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7032 - loss: 0.5728 - val_accuracy: 0.6969 - val_loss: 0.5862\n","Epoch 44/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7066 - loss: 0.6001 - val_accuracy: 0.7047 - val_loss: 0.5945\n","Epoch 45/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7015 - loss: 0.5704 - val_accuracy: 0.6929 - val_loss: 0.5882\n","Epoch 46/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7313 - loss: 0.5705 - val_accuracy: 0.7087 - val_loss: 0.6148\n","Epoch 47/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7067 - loss: 0.5888 - val_accuracy: 0.7008 - val_loss: 0.5711\n","Epoch 48/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7355 - loss: 0.5684 - val_accuracy: 0.7126 - val_loss: 0.5797\n","Epoch 49/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7307 - loss: 0.5558 - val_accuracy: 0.7047 - val_loss: 0.5676\n","Epoch 50/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6917 - loss: 0.6146 - val_accuracy: 0.7087 - val_loss: 0.5752\n","Epoch 51/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7226 - loss: 0.5646 - val_accuracy: 0.7047 - val_loss: 0.5688\n","Epoch 52/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7346 - loss: 0.5451 - val_accuracy: 0.7047 - val_loss: 0.5766\n","Epoch 53/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7133 - loss: 0.5645 - val_accuracy: 0.6890 - val_loss: 0.6063\n","Epoch 54/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7275 - loss: 0.5603 - val_accuracy: 0.7087 - val_loss: 0.5659\n","Epoch 55/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6953 - loss: 0.5549 - val_accuracy: 0.7087 - val_loss: 0.5872\n","Epoch 56/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6809 - loss: 0.5886 - val_accuracy: 0.6969 - val_loss: 0.5738\n","Epoch 57/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7301 - loss: 0.5680 - val_accuracy: 0.7087 - val_loss: 0.5843\n","Epoch 58/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7417 - loss: 0.5318 - val_accuracy: 0.7047 - val_loss: 0.5633\n","Epoch 59/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7406 - loss: 0.5270 - val_accuracy: 0.7008 - val_loss: 0.6028\n","Epoch 60/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7552 - loss: 0.5290 - val_accuracy: 0.6811 - val_loss: 0.6023\n","Epoch 61/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7113 - loss: 0.5822 - val_accuracy: 0.6969 - val_loss: 0.5877\n","Epoch 62/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6957 - loss: 0.5747 - val_accuracy: 0.7047 - val_loss: 0.5620\n","Epoch 63/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7281 - loss: 0.5600 - val_accuracy: 0.7087 - val_loss: 0.5609\n","Epoch 64/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7253 - loss: 0.5403 - val_accuracy: 0.7008 - val_loss: 0.5622\n","Epoch 65/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7206 - loss: 0.5735 - val_accuracy: 0.7008 - val_loss: 0.5930\n","Epoch 66/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7353 - loss: 0.5526 - val_accuracy: 0.7087 - val_loss: 0.5902\n","Epoch 67/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7492 - loss: 0.5383 - val_accuracy: 0.7126 - val_loss: 0.5708\n","Epoch 68/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7012 - loss: 0.5840 - val_accuracy: 0.7047 - val_loss: 0.5876\n","Epoch 69/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7192 - loss: 0.5852 - val_accuracy: 0.7008 - val_loss: 0.5720\n","Epoch 70/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7051 - loss: 0.5928 - val_accuracy: 0.7126 - val_loss: 0.5797\n","Epoch 71/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6997 - loss: 0.5819 - val_accuracy: 0.6890 - val_loss: 0.5931\n","Epoch 72/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7248 - loss: 0.5387 - val_accuracy: 0.6811 - val_loss: 0.6109\n","Epoch 73/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7088 - loss: 0.5884 - val_accuracy: 0.7126 - val_loss: 0.5626\n","Epoch 74/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7378 - loss: 0.5083 - val_accuracy: 0.7205 - val_loss: 0.5813\n","Epoch 75/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7450 - loss: 0.5582 - val_accuracy: 0.7126 - val_loss: 0.5820\n","Epoch 76/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7018 - loss: 0.5765 - val_accuracy: 0.7087 - val_loss: 0.5665\n","Epoch 77/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7397 - loss: 0.5254 - val_accuracy: 0.7047 - val_loss: 0.5553\n","Epoch 78/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7095 - loss: 0.5562 - val_accuracy: 0.6339 - val_loss: 0.6816\n","Epoch 79/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7023 - loss: 0.6063 - val_accuracy: 0.7126 - val_loss: 0.5618\n","Epoch 80/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7033 - loss: 0.5721 - val_accuracy: 0.7126 - val_loss: 0.5548\n","Epoch 81/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6852 - loss: 0.5831 - val_accuracy: 0.6969 - val_loss: 0.5561\n","Epoch 82/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7052 - loss: 0.5780 - val_accuracy: 0.6969 - val_loss: 0.5613\n","Epoch 83/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7416 - loss: 0.5201 - val_accuracy: 0.7165 - val_loss: 0.5670\n","Epoch 84/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7137 - loss: 0.5551 - val_accuracy: 0.6929 - val_loss: 0.5531\n","Epoch 85/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7019 - loss: 0.5554 - val_accuracy: 0.7126 - val_loss: 0.5774\n","Epoch 86/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7247 - loss: 0.5477 - val_accuracy: 0.6850 - val_loss: 0.6266\n","Epoch 87/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.5635 - val_accuracy: 0.7205 - val_loss: 0.5618\n","Epoch 88/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7174 - loss: 0.5530 - val_accuracy: 0.7205 - val_loss: 0.5849\n","Epoch 89/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7030 - loss: 0.5606 - val_accuracy: 0.6969 - val_loss: 0.5555\n","Epoch 90/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7135 - loss: 0.5839 - val_accuracy: 0.7008 - val_loss: 0.5533\n","Epoch 91/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7222 - loss: 0.5595 - val_accuracy: 0.7087 - val_loss: 0.5604\n","Epoch 92/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7485 - loss: 0.5298 - val_accuracy: 0.7323 - val_loss: 0.5632\n","Epoch 93/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7344 - loss: 0.5443 - val_accuracy: 0.7008 - val_loss: 0.5560\n","Epoch 94/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7182 - loss: 0.5425 - val_accuracy: 0.7008 - val_loss: 0.5533\n","Epoch 95/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7219 - loss: 0.5469 - val_accuracy: 0.7087 - val_loss: 0.5521\n","Epoch 96/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7205 - loss: 0.5407 - val_accuracy: 0.7126 - val_loss: 0.5745\n","Epoch 97/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7288 - loss: 0.5218 - val_accuracy: 0.7008 - val_loss: 0.5763\n","Epoch 98/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.5491 - val_accuracy: 0.6929 - val_loss: 0.5790\n","Epoch 99/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.5213 - val_accuracy: 0.7087 - val_loss: 0.5566\n","Epoch 100/100\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7324 - loss: 0.5156 - val_accuracy: 0.7047 - val_loss: 0.5520\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7c19306a2e60>"]},"metadata":{},"execution_count":6}],"source":["# Fit the model\n","model.fit(X, Y, validation_split=0.33, epochs=100, batch_size=20)\n","\n","# train and test is not used u can also used no problem\n","# validity --> test 33%\n","# epchos ---> stop overfitting\n","# batch_size=20 ( Mini batch it take some 20 samples)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DVeHmbRDp3lZ","outputId":"8833bcc0-442e-4167-d264-ddcb71b96e4b","executionInfo":{"status":"ok","timestamp":1732641395508,"user_tz":-330,"elapsed":17,"user":{"displayName":"Jaya Prakash","userId":"11498912294217054029"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7248 - loss: 0.5452 \n","compile_metrics: 72.92%\n"]}],"source":["# evaluate the model\n","scores = model.evaluate(X, Y)\n","print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","\n","# model.evaluate() function --> evaluate the performance of the trained model on a given dataset\n","# This line print the accuracy of the model.\n","\n","# print(\"%s: %.2f%%\" % (...)) output string to display the metric name ('accuracy') followed by the accuracy value as a percentage.\n","\n","# model.metrics_names[1] refers to the second metric, which is 'accuracy' in this case, since 'loss' is usually the first metric\n","# scores[1] refers to the second value in the scores list, which is the accuracy value.\n","# Complete matrics --- Accuracy is 72.48"]},{"cell_type":"code","source":["scores\n","\n","# 0.5329843163490295   Loss,\n","# 0.7291666865348816   Compile matrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FpyzLxK-sSJv","outputId":"27bd723c-15db-4aba-d18d-3f5a651da1c5","executionInfo":{"status":"ok","timestamp":1732641395508,"user_tz":-330,"elapsed":10,"user":{"displayName":"Jaya Prakash","userId":"11498912294217054029"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.5329843163490295, 0.7291666865348816]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8FnE9TR3p3lZ"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}